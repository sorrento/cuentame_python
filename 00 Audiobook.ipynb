{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\milen\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils import seleccion_txt, txt_read, get_fakes, cabeza_y_cola, corta\n",
    "from ut.textmining import get_word_matrix\n",
    "\n",
    "PATH_CALIBRE = 'c:/Users/milen/Biblioteca de calibre/'\n",
    "lang = \"ES\"  # >>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Summary creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 libros de referencia para hacer el tf-idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** La ultima fecha de ficheros es:  20230711\n",
      "                                                     0\n",
      "0             V. I. Lenin. - Materialismo y e - ().txt\n",
      "1                          Mi lucha - Adolf Hitler.txt\n",
      "2        El Conde de Montecristo - Alejandro Dumas.txt\n",
      "3       La casa de los espiritus - Allende, Isabel.txt\n",
      "4         La Araucana - Alonso de Ercilla Y Zuniga.txt\n",
      "..                                                 ...\n",
      "163  Heaven Is for Real_ A Little Bo - Todd Burpo; ...\n",
      "164        La esfinge de los hielos - Verne, Julio.txt\n",
      "165           El planeta americano - Vicente Verdu.txt\n",
      "166  El hombre en busca de sentido - Viktor Frankl.txt\n",
      "167                  Homo Deus - Yuval Noah Harari.txt\n",
      "\n",
      "[168 rows x 1 columns]\n",
      "                                                    0\n",
      "0      La casa de los espiritus - Allende, Isabel.txt\n",
      "1                  Las Mil y una Noches - Anonimo.txt\n",
      "2    2001. Una odisea espacial - Arthur C. Clarke.txt\n",
      "3         En las profundidades - Arthur C. Clarke.txt\n",
      "4                     Factotum - Charles Bukowski.txt\n",
      "5             Estado de miedo - Crichton, Michael.txt\n",
      "6   Hasta luego y gracias por el pe - Douglas Adam...\n",
      "7                   Prometeo encadenado - Esquilo.txt\n",
      "8       El gran Gatsby - Francis Scott Fitzgerald.txt\n",
      "9   Cronica de una muerte anunciada - Gabriel Garc...\n",
      "10  Enciclopedia de las curiosidade - Gregorio Dov...\n",
      "11      Y las montanas hablaron - Khaled Hosseini.txt\n",
      "12                 Mujercitas - Louisa May Alcott.txt\n",
      "13          Hacedor de estrellas - Olaf Stapledon.txt\n",
      "14  Camino al futuro - Peter Rinearson Bill Gates.txt\n",
      "15        Los juegos del hambre - Suzanne Collins.txt\n",
      "16        La esfinge de los hielos - Verne, Julio.txt\n",
      "17  El hombre en busca de sentido - Viktor Frankl.txt\n"
     ]
    }
   ],
   "source": [
    "key = 'freakonomics'  # keyword para seleccionar el libro\n",
    "\n",
    "last, all_ = seleccion_txt(PATH_CALIBRE)  # trae todoslos título de libros en español\n",
    "# get the filename with path from all_ list\n",
    "file = [x for x in all_ if key in x.lower()][0]  # elejimos el primero\n",
    "\n",
    "date_es = 20220703 if lang == 'EN' else 20200504\n",
    "files_es, _ = seleccion_txt(PATH_CALIBRE, fecha=date_es)\n",
    "files = [file] + files_es # usamos libros para generar el corpus para el tfidf\n",
    "doc_list = [txt_read(x) for x in files] # lee los archivos y los pone en una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_matrix, vocab, _ = get_word_matrix(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_fake, di_counts = get_fakes(doc_list, files, vector_matrix, vocab, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_fake = {0: dic_fake[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(dic_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = {dic_fake[k]['title']: dic_fake[k] for k in dic_fake}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from ipywidgets import fixed, interactive\n",
    "from ut.images import crop\n",
    "from utils import get_books, get_image_path, upload_lib_summary, get_book_datas\n",
    "from ut.io import get_filename\n",
    "from ut.base import json_read\n",
    "\n",
    "PATH_CALIBRE = 'c:/Users/milen/Biblioteca de calibre/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image= get_image_path(file)\n",
    "titulo = get_filename(file, True).split(' - ')[0]\n",
    "print(titulo) #ojo que puede estar cortado por Calire si es muy largo... quizas deberíamos cogerlo de la carpeta..\n",
    "im = Image.open(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if im.size[0] > 700:\n",
    "    im = im.reduce(2)\n",
    "im.reduce(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = interactive(crop, f=(0.1, 1, 0.05),\n",
    "                sx=(1, int(im.size[0] * .5)),\n",
    "                sy=(1, int(im.size[1] * .9)),\n",
    "                img=fixed(im))\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = u.result.size[0]\n",
    "a = 200\n",
    "b = min(si, 2 * a)\n",
    "im_low = u.result.resize((a, a))\n",
    "im_hi = u.result.resize((b, b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'data_out/_images/{}/{}.jpg'\n",
    "im_low.save(base.format('low', titulo))\n",
    "im_hi.save(base.format('hi', titulo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# otherb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texto, img, titulo, d_summary = get_book_datas('Freak')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir en partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dic_fake[0]['path']\n",
    "texto = txt_read(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# te qudas con la i del lo que parece el final del libro\n",
    "partes, df = cabeza_y_cola(texto, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = 802  # >>>\n",
    "ini = 15  # >>>\n",
    "\n",
    "# d_summary['min'], d_summary['max'] = ini, fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partes, df = corta(partes, df, ini, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().rename(columns={'index': 'i'})\n",
    "df['ii'] = 0 # para identificar dentro de un párrafo largo que romperemos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from ut.base import json_read, json_save, make_folder, json_update\n",
    "from utils import crea_capsulas_max, get_parrafos, get_final_parrfs, speakers_test, get_df_capitulos, \\\n",
    "    get_dic_capitulos, update_di_capi, procesa_capitulo, get_book_datas, SUMMARIES_JSON, sample_speaker, test_voices_en, \\\n",
    "    CONTENT_JSON\n",
    "from ut.textmining import palabras_representativas\n",
    "\n",
    "LIM = 850  # largo de las cápsulas, límite de lo que puede leer el sinte\n",
    "\n",
    "final, partes = get_final_parrfs(df, LIM)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_capsulas = crea_capsulas_max(partes, final, lmax=LIM, verbose=False)\n",
    "caps = ['.\\n'.join(d_capsulas[x]['texto']) for x in d_capsulas]  # todo probar si sintetizador lee punto aparte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps[12]  # las cápsulas son las que puede leer de una sola vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capitulos = get_df_capitulos(caps)\n",
    "df_capitulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_capitulos = get_dic_capitulos(df_capitulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitulos = ['\\n '.join(d_capitulos[cap]['capsulas']) for cap in d_capitulos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(j.keys())[0]\n",
    "d_summary = j[k]\n",
    "capitulos_titles = palabras_representativas(capitulos,\n",
    "                                            l_exclude=d_summary['names'],\n",
    "                                            max_df=.4,  # .8  proporción de documentos. si lo bajamos quitamos los muy frecuentes\n",
    "                                            min_df=.2)  # .2  % de docs. Si lo subo quito palabras poco frecuentes\n",
    "capitulos_titles\n",
    "update_di_capi(d_capitulos, capitulos_titles, d_summary, titulo)\n",
    "path_book = make_folder('data_out/' + titulo + '/')\n",
    "json_save(d_capitulos, path_book + CONTENT_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_capitulos=json_read(path_book + CONTENT_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml',\n",
    "                               'latest_silero_models.yml',\n",
    "                               progress=False)\n",
    "\n",
    "models = OmegaConf.load('latest_silero_models.yml')\n",
    "available_languages = list(models.tts_models.keys())\n",
    "\n",
    "for lang in available_languages:\n",
    "    modeli = list(models.tts_models.get(lang).keys())\n",
    "    print(f'Available models for {lang}: {modeli}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuración\n",
    "language = d_summary['idioma'].lower()\n",
    "model_id = 'v3_es' if language == 'es' else 'v3_en'\n",
    "\n",
    "sample_rate = 48000\n",
    "put_accent = True\n",
    "put_yo = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos el modelo\n",
    "device = torch.device('cpu')  # or cuda, pero no me funciona\n",
    "\n",
    "model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                     model='silero_tts',\n",
    "                                     language=language,\n",
    "                                     speaker=model_id)\n",
    "model.to(device)  # gpu or cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps = [x for x in model.speakers if x != 'random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_capitulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the keys to int\n",
    "d_capitulos = {int(k): v for k, v in d_capitulos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import speakers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if language == 'es':\n",
    "    speakers_test(model,\n",
    "                  txt=d_capitulos[1]['capsulas'][0][:450],\n",
    "                  lan='es'\n",
    "#                  txt='Millonarios por una semana.\\n Cuando no se tiene una chaucha en el bolsillo, no es muy amplia la gama de actividades elegibles para matar el tiempo. Con Diego y Vittorio nos juntábamos casi todos los d'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
